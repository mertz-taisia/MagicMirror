{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (0.10.14)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: absl-py in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from mediapipe) (0.4.34)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from mediapipe) (0.4.34)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from mediapipe) (2.1.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from mediapipe) (4.25.5)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from jax->mediapipe) (0.5.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from jax->mediapipe) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from matplotlib->mediapipe) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from matplotlib->mediapipe) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbimporter in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from nbformat) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from jsonschema>=2.6->nbformat) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.20.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (308)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygltflib in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (1.16.3)\n",
      "Requirement already satisfied: dataclasses-json>=0.0.25 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from pygltflib) (0.6.7)\n",
      "Requirement already satisfied: deprecated in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from pygltflib) (1.2.15)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from dataclasses-json>=0.0.25->pygltflib) (3.24.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from dataclasses-json>=0.0.25->pygltflib) (0.9.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from deprecated->pygltflib) (1.17.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json>=0.0.25->pygltflib) (24.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib) (4.12.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trimesh in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (4.5.3)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from trimesh) (2.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyrender in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (0.1.45)\n",
      "Requirement already satisfied: freetype-py in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from pyrender) (2.5.1)\n",
      "Requirement already satisfied: imageio in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from pyrender) (2.37.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from pyrender) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from pyrender) (2.1.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from pyrender) (10.4.0)\n",
      "Requirement already satisfied: pyglet>=1.4.10 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from pyrender) (2.1.0)\n",
      "Requirement already satisfied: PyOpenGL==3.1.0 in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from pyrender) (3.1.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from pyrender) (1.14.1)\n",
      "Requirement already satisfied: six in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from pyrender) (1.16.0)\n",
      "Requirement already satisfied: trimesh in c:\\users\\15rak\\documents\\magicmirror\\env\\lib\\site-packages (from pyrender) (4.5.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nbimporter\n",
    "!pip install nbformat\n",
    "!pip install pygltflib\n",
    "!pip install trimesh\n",
    "!pip install pyrender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from collections import deque\n",
    "import logging\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bone hip rotation:[0.0, 0.636066041716249, 0.0, 0.9999982670293956] and translation:[0.6389742493629456, 1.097416877746582, 0.001640230417251587]\n",
      "bone Bone.002 rotation:[0.004490206018090248, 0.01330167893320322, 0.11290524154901505, 0.9935065507888794] and translation:[-3.725290298461914e-09, 1.0250910520553589, 0.0]\n",
      "bone neck rotation:[-0.06400275230407715, -0.2615671157836914, -0.16527314484119415, 0.9487735033035278] and translation:[-2.922024577856064e-08, 1.621514081954956, -9.313225746154785e-10]\n",
      "bone Bone.004 rotation:[-0.7730085253715515, -0.04162666201591492, 0.03303844854235649, 0.632165789604187] and translation:[-2.922024577856064e-08, 1.621514081954956, -9.313225746154785e-10]\n",
      "bone leftShoulder rotation:[-0.6667152620573763, 0.0, -0.45174673138591664, 0.7453125246094848] and translation:[-1.1175870895385742e-07, 0.9313156604766846, 1.9185245037078857e-07]\n",
      "bone leftForearm rotation:[0.008933612145483494, 0.12852653861045837, -0.035434797406196594, 0.9910325407981873] and translation:[4.470348358154297e-08, 1.0044176578521729, 8.940696716308594e-08]\n",
      "bone Bone.005 rotation:[0.781658947467804, 0.005751630757004023, -0.014941323548555374, 0.623500645160675] and translation:[-2.922024577856064e-08, 1.621514081954956, -9.313225746154785e-10]\n",
      "bone rightShoulder rotation:[0.5841406512491897, 0.0, 0.4834421852838105, 0.8116524499797759] and translation:[-2.2351741790771484e-08, 0.8172944188117981, -1.9883736968040466e-07]\n",
      "bone rightForearm rotation:[-0.007462999576131137, 0.9695081441482093, -0.004200130584383714, 0.24490941380579026] and translation:[-4.470348358154297e-08, 1.0127285718917847, 2.3096799850463867e-07]\n",
      "In list\n",
      "Position Accessor(extensions={}, extras={}, bufferView=0, byteOffset=0, componentType=5126, normalized=False, count=9192, type='VEC3', sparse=None, max=[1.0807095766067505, 2.9985105991363525, 1.5579530000686646], min=[-0.8559107184410095, -0.38889896869659424, -1.6121143102645874], name=None)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import trimesh\n",
    "import pyrender\n",
    "from pygltflib import GLTF2\n",
    "\n",
    "gltf = GLTF2().load(\"3D\\magicmirror.glb\")\n",
    "m_index = 0\n",
    "material = gltf.materials[m_index]\n",
    "material.alphaMode = \"MASK\"\n",
    "material.alphaCutoff=0.5\n",
    "for node_idx, node in enumerate(gltf.nodes):\n",
    "    if node.skin is not None:\n",
    "        joints = gltf.skins[node.skin].joints\n",
    "        bone_list=[]\n",
    "        for joint in joints:\n",
    "            joint_node = gltf.nodes[joint]\n",
    "            bone_list.append(joint_node)\n",
    "    if node.children:\n",
    "        node.children = [child for child in node.children if child != 9 ]\n",
    "for bone in bone_list:\n",
    "    print(f\"bone {bone.name} rotation:{bone.rotation} and translation:{bone.translation}\")\n",
    "if 9 not in gltf.scenes[0].nodes:\n",
    "    gltf.scenes[0].nodes.append(9)\n",
    "    print(\"Not in list\")\n",
    "else:\n",
    "    print(\"In list\")\n",
    "\n",
    "# Access the first mesh in the scene (or iterate if you have more meshes)\n",
    "mesh = gltf.meshes[0]\n",
    "for primitive in mesh.primitives:\n",
    "    position = gltf.accessors[primitive.attributes.POSITION]\n",
    "    print(f\"Position {position}\")\n",
    "gltf.save(\"3D\\magicmirror.glb\")\n",
    "\n",
    "def active_update():\n",
    "    shirt_mesh = trimesh.load('3D\\magicmirror.glb')\n",
    "    scene = pyrender.Scene()\n",
    "    scene.add(pyrender.Mesh.from_trimesh(trimesh.util.concatenate(shirt_mesh.dump())))\n",
    "    camera = pyrender.PerspectiveCamera(yfov=60, aspectRatio=1.0)\n",
    "    pose = np.eye(4)\n",
    "    pose[:3,3]=[0,0,2]\n",
    "    scene.add(camera, pose=pose)\n",
    "\n",
    "    renderer = pyrender.OffscreenRenderer(viewport_width=640,viewport_height=480)\n",
    "    color,_=renderer.render(scene)\n",
    "\n",
    "    color_bgr=cv2.cvtColor(color, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    cv2.imshow(\"gltf\",color_bgr)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Swipe Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leftSwipeDetection(leftWristLocations):\n",
    "    return leftWristLocations[0][0] - leftWristLocations[-1][0] > 100\n",
    "\n",
    "def rightSwipeDetection(rightWristLocations):\n",
    "    return rightWristLocations[-1][0] - rightWristLocations[0][0] > 100\n",
    "\n",
    "def upSwipeDetection(rightWristLocations):\n",
    "    return rightWristLocations[0][1] - rightWristLocations[-1][1] > 100\n",
    "\n",
    "\n",
    "# Configure the logger\n",
    "logging.basicConfig(\n",
    "    filename='debug_log.txt',  # Output file\n",
    "    level=logging.DEBUG,       # Logging level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Log message format\n",
    "    filemode='w'  # Overwrite the log file each run (change to 'a' to append)\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mapTops(pose_points, img):\n",
    "    # Calculate the distance between the shoulders (pose_points[0] and pose_points[1])\n",
    "    shoulder_distance = math.sqrt((pose_points[1][0] - pose_points[0][0]) ** 2 + (pose_points[1][1] - pose_points[0][1]) ** 2)\n",
    "    \n",
    "    # Scale offsets based on shoulder distance\n",
    "    shoulder_scale_factor = shoulder_distance / 250  # Adjust the denominator based on your needs; it's a scaling factor.\n",
    "    shoulder_x_offset = int(100 * shoulder_scale_factor)\n",
    "    hip_x_offset = int(180 * shoulder_scale_factor)\n",
    "    shoulder_y_offset = int(50 * shoulder_scale_factor)\n",
    "    \n",
    "    # Calculate the height-to-width ratio of the input image\n",
    "    heightToWidth = img.shape[0] / img.shape[1]\n",
    "    width = int(math.fabs(pose_points[1][0] - pose_points[0][0]) * heightToWidth)\n",
    "    height = int(width * heightToWidth)\n",
    "    \n",
    "    src = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype='float32')\n",
    "    \n",
    "    dest = np.array([\n",
    "        [pose_points[0][0] + shoulder_x_offset, pose_points[0][1] - shoulder_y_offset], # Left shoulder\n",
    "        [pose_points[1][0] - shoulder_x_offset, pose_points[1][1] - shoulder_y_offset], # Right shoulder\n",
    "        [pose_points[3][0] - hip_x_offset, pose_points[3][1]], # Right hip\n",
    "        [pose_points[2][0] + hip_x_offset, pose_points[2][1]] # Left hip\n",
    "    ], dtype='float32')\n",
    "    \n",
    "    # Logging pose points and their mapping\n",
    "    logger.debug(f\"Og Pose Points: {pose_points}\")\n",
    "    logger.debug(f\"Source Points (src): {src}\")\n",
    "    logger.debug(f\"Destination Points (dest): {dest}\")\n",
    "    \n",
    "    transform = cv2.getPerspectiveTransform(src, dest)\n",
    "    img = cv2.resize(img, (width, height))\n",
    "    \n",
    "    return img, transform\n",
    "\n",
    "\n",
    "def mapBottoms(pose_points, img):\n",
    "    # Calculate the distance between the shoulders (pose_points[0] and pose_points[1])\n",
    "    hip_distance = math.sqrt((pose_points[1][0] - pose_points[0][0]) ** 2 + (pose_points[1][1] - pose_points[0][1]) ** 2)\n",
    "    \n",
    "    # Scale offsets based on shoulder distance\n",
    "    hip_scale_factor = hip_distance / 250  # Adjust the denominator based on your needs; it's a scaling factor.\n",
    "    hip_x_offset = int(150 * hip_scale_factor) # 180 -> 150\n",
    "    ankle_x_offset = int(150 * hip_scale_factor) # 200 -> 150\n",
    "    # ankle_y_offset = int(200 * hip_scale_factor)\n",
    "    hip_y_offset = int(70 * hip_scale_factor) # 10 -> 70\n",
    "    \n",
    "    # Calculate the height-to-width ratio of the input image\n",
    "    heightToWidth = img.shape[0] / img.shape[1]\n",
    "    width = int(math.fabs(pose_points[1][0] - pose_points[0][0]) * heightToWidth)\n",
    "    height = int(width * heightToWidth)\n",
    "    \n",
    "    src = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype='float32')\n",
    "    \n",
    "    dest = np.array([\n",
    "        [pose_points[0][0] + hip_x_offset, pose_points[0][1] - hip_y_offset], # Left shoulder\n",
    "        [pose_points[1][0] - hip_x_offset, pose_points[1][1] - hip_y_offset], # Right shoulder\n",
    "        [pose_points[3][0] - ankle_x_offset, pose_points[3][1]], # Right hip\n",
    "        [pose_points[2][0] + ankle_x_offset, pose_points[2][1]] # Left hip\n",
    "    ], dtype='float32')\n",
    "    \n",
    "    # Logging pose points and their mapping\n",
    "    logger.debug(f\"Og Pose Points: {pose_points}\")\n",
    "    logger.debug(f\"Source Points (src): {src}\")\n",
    "    logger.debug(f\"Destination Points (dest): {dest}\")\n",
    "    \n",
    "    transform = cv2.getPerspectiveTransform(src, dest)\n",
    "    img = cv2.resize(img, (width, height))\n",
    "    \n",
    "    return img, transform\n",
    "\n",
    "def overlay_clothing(frame, clothing_img, transform):\n",
    "    # Debugging: Shape of inputs before transformation\n",
    "    logger.debug(f\"Frame shape: {frame.shape}, Clothing image shape: {clothing_img.shape}\")\n",
    "\n",
    "    # Warp the clothing image to match the person's pose\n",
    "    transformed_clothing = cv2.warpPerspective(clothing_img, transform, (frame.shape[1], frame.shape[0]))\n",
    "    logger.debug(f\"Transformed clothing image shape: {transformed_clothing.shape}\")\n",
    "\n",
    "    # Handle alpha blending if clothing image has an alpha channel\n",
    "    if transformed_clothing.shape[-1] == 4:  # If the image has an alpha channel\n",
    "        logger.debug(\"Clothing image has an alpha channel.\")\n",
    "        alpha_channel = transformed_clothing[:, :, 3] / 255.0  # Normalize alpha channel to 0-1\n",
    "        for c in range(0, 3):  # Iterate over the RGB channels\n",
    "            frame[:, :, c] = (1.0 - alpha_channel) * frame[:, :, c] + alpha_channel * transformed_clothing[:, :, c]\n",
    "    else:\n",
    "        logger.debug(\"Clothing image does not have an alpha channel.\")\n",
    "        # Directly overlay the transformed clothing (no transparency)\n",
    "        mask = transformed_clothing > 0  # Consider any non-zero pixel as part of the clothing\n",
    "        frame[mask] = transformed_clothing[mask]\n",
    "\n",
    "    logger.debug(\"Overlay operation completed.\")\n",
    "    return frame\n",
    "\n",
    "def capture_and_rotate_frame(camera, angle):\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        return None\n",
    "\n",
    "    # Rotate the frame according to the specified angle\n",
    "    if angle == 90:\n",
    "        frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    elif angle == -90:\n",
    "        frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    elif angle == 180:\n",
    "        frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftWristLocations = deque(maxlen=10)\n",
    "rightWristLocations = deque(maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during pose estimation or clothing mapping: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4155: error: (-215:Assertion failed) inv_scale_x > 0 in function 'cv::resize'\n",
      "\n",
      "An error occurred during pose estimation or clothing mapping: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4155: error: (-215:Assertion failed) inv_scale_x > 0 in function 'cv::resize'\n",
      "\n",
      "top array\n",
      "bottom array\n",
      "top array\n"
     ]
    }
   ],
   "source": [
    "desktop = False\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "angle = 0 if desktop else -90\n",
    "\n",
    "\n",
    "last_left_swipe_time = 0\n",
    "last_right_swipe_time = 0\n",
    "swipe_delay = 1\n",
    "\n",
    "clothing_tops = [\"White T-shirt\", \"Blue T-shirt\", \"Red T-shirt\"]\n",
    "clothing_bottoms = [\"Green Pants\", \"Tan Slacks\", \"White Pants\"]\n",
    "\n",
    "clothing_tops_index = 0\n",
    "clothing_bottoms_index = 0\n",
    "clothing_top_selected = False\n",
    "\n",
    "## Setup mediapipe instanceq\n",
    "with mp_pose.Pose(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as pose:\n",
    "    while True:\n",
    "        # frame = capture_and_rotate_frame(cap, angle)\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame is None: \n",
    "            print(\"Frame capture returned None; ending loop\")\n",
    "            break\n",
    "        \n",
    "        #frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "        listTops = os.listdir(\"top_images\")\n",
    "        listBottoms = os.listdir(\"bottom_images\")\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            if results.pose_landmarks:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "                # Get coordinates\n",
    "                left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "                right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "                \n",
    "                left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "\n",
    "                left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "                \n",
    "                left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "                right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "                norm_coord = [frame.shape[0], frame.shape[1]] if desktop else [frame.shape[1], frame.shape[0]]\n",
    "\n",
    "                # Normalizes Coordinates\n",
    "                left_shoulder_coords = tuple(np.multiply(left_shoulder, norm_coord).astype(int))\n",
    "                right_shoulder_coords = tuple(np.multiply(right_shoulder, norm_coord).astype(int))\n",
    "\n",
    "                left_hip_coords = tuple(np.multiply(left_hip, norm_coord).astype(int))\n",
    "                right_hip_coords = tuple(np.multiply(right_hip, norm_coord).astype(int)) \n",
    "                \n",
    "                left_ankle_coords = tuple(np.multiply(left_ankle, norm_coord).astype(int))\n",
    "                right_ankle_coords = tuple(np.multiply(right_ankle, norm_coord).astype(int))\n",
    "\n",
    "                upper_coords = [left_shoulder_coords, right_shoulder_coords, left_hip_coords, right_hip_coords]\n",
    "                lower_coords = [left_hip_coords, right_hip_coords, left_ankle_coords, right_ankle_coords]\n",
    "\n",
    "                #testing***\n",
    "                \n",
    "               \n",
    "                for bone in bone_list:\n",
    "                    if bone.name == \"rightShoulder\":\n",
    "                        left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].z]\n",
    "                        # left_elbow_coords = tuple(np.multiply(left_elbow, norm_coord).item())\n",
    "                        y = left_elbow[1]-left_shoulder[1]\n",
    "                        x = left_elbow[0]-left_shoulder[0]\n",
    "                        z = left_elbow[2]-landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z\n",
    "                        d = math.sqrt(math.pow(y,2)+math.pow(x,2))\n",
    "                        #find rotation angle of the bone\n",
    "                        \n",
    "                        bone.rotation = [math.sin(math.asin(y/d)/2),0,math.sin(math.atan(x/z)/2),math.cos(math.asin(y/d)/2)]\n",
    "                        # bone.translation = [0.078867807894,left_shoulder[0],left_shoulder[1]]\n",
    "                        \n",
    "                for bone in bone_list:\n",
    "                    if bone.name == \"leftShoulder\":\n",
    "                        right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].z]\n",
    "                        # right_elbow_coords = tuple(np.multiply(right_elbow, norm_coord).item())\n",
    "                        y = right_elbow[1]-right_shoulder[1]\n",
    "                        x = right_elbow[0]-right_shoulder[0]\n",
    "                        z = right_elbow[2]-landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].z\n",
    "                        d = math.sqrt(math.pow(y,2)+math.pow(x,2))\n",
    "                        #find rotation angle of the bone\n",
    "                        \n",
    "                        bone.rotation = [-math.sin(math.asin(y/d)/2),0,-math.sin(math.atan(x/z)/2),math.cos(math.asin(y/d)/2)]\n",
    "                        # bone.translation = [-0.117773614, right_shoulder[0],right_shoulder[1]]\n",
    "                for bone in bone_list:\n",
    "                    if bone.name == \"hip\":#fix hip rotation\n",
    "                        z = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].z-landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].z\n",
    "                        y = right_hip[1]-left_hip[1]\n",
    "                        x = right_hip[0]-left_hip[0]\n",
    "                        d = math.sqrt(math.pow(y,2)+math.pow(x,2))\n",
    "                        if(x>=0):\n",
    "                            bone.rotation = [0,math.sin(math.atan(x/z)/2),0,math.cos(math.asin(y/d)/2)]\n",
    "                        elif(x<0):\n",
    "                            bone.rotation = [0,1+math.sin(math.atan(x/z)/2),0,math.cos(math.asin(y/d)/2)]\n",
    "                        # bone.translation = [(left_hip[0] + right_hip[0])/2,(left_hip[1] + right_hip[1])/2, (landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].z + landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].z)/2]\n",
    "                bone.translation = [float(val) for val in bone.translation]\n",
    "                bone.rotation = [float(val)/np.linalg.norm(bone.rotation) for val in bone.rotation]\n",
    "                \n",
    "                try:\n",
    "                    gltf.save_binary(\"3D/magicmirror.glb\")\n",
    "                    # active_update()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving GLB file: {e}\")\n",
    "\n",
    "                #end of testing***\n",
    "\n",
    "                for point in [left_shoulder_coords, right_shoulder_coords, left_hip_coords, right_hip_coords]:\n",
    "                    cv2.circle(frame, point, 5, (0, 255, 0), -1)\n",
    "\n",
    "                bottom_image = cv2.imread(os.path.join(\"bottom_images\", listBottoms[clothing_bottoms_index]),cv2.IMREAD_UNCHANGED)\n",
    "                bottom_image, transform = mapBottoms(lower_coords, bottom_image)\n",
    "                frame = overlay_clothing(frame, bottom_image, transform)\n",
    "                \n",
    "                top_image = cv2.imread(os.path.join(\"top_images\", listTops[clothing_tops_index]),cv2.IMREAD_UNCHANGED)\n",
    "                top_image, transform = mapTops(upper_coords, top_image)\n",
    "                frame = overlay_clothing(frame, top_image, transform)\n",
    "\n",
    "\n",
    "                # cv2.imshow(\"Transformed shirt\", top_image)\n",
    "                # cv2.imshow(\"Transformed bottom\", bottom_image)\n",
    "                \n",
    "                cv2.imshow(\"Overlayed Clothing\", frame)\n",
    "               \n",
    "                \n",
    "                    \n",
    "                \n",
    "                # cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "               \n",
    "            else:\n",
    "                print(\"No pose landmarks detected\")\n",
    "                continue\n",
    "            \n",
    "            # Normalizes Coordinates\n",
    "            left_wrist_coords = tuple(np.multiply(left_wrist, [640, 480]).astype(int))\n",
    "            right_wrist_coords = tuple(np.multiply(right_wrist, [640, 480]).astype(int))\n",
    "\n",
    "            leftWristLocations.append(left_wrist_coords)\n",
    "            rightWristLocations.append(right_wrist_coords)\n",
    "            \n",
    "            current_time = time.time()\n",
    "\n",
    "            if leftSwipeDetection(leftWristLocations):\n",
    "                if current_time - last_left_swipe_time > swipe_delay:\n",
    "                    last_left_swipe_time = current_time\n",
    "                    if clothing_top_selected:\n",
    "                        if clothing_tops_index == 0:\n",
    "                            clothing_tops_index = len(clothing_tops) - 1\n",
    "                        else:\n",
    "                            clothing_tops_index -= 1\n",
    "                    else:\n",
    "                        if clothing_bottoms_index == 0:\n",
    "                            clothing_bottoms_index = len(clothing_bottoms) - 1\n",
    "                        else:\n",
    "                            clothing_bottoms_index -= 1\n",
    "                        \n",
    "                \n",
    "            if rightSwipeDetection(rightWristLocations):\n",
    "                if current_time - last_right_swipe_time > swipe_delay:\n",
    "                    last_right_swipe_time = current_time\n",
    "                    if clothing_top_selected:\n",
    "                        if clothing_tops_index == len(clothing_tops) - 1 :\n",
    "                            clothing_tops_index = 0\n",
    "                            \n",
    "                        else:\n",
    "                            clothing_tops_index += 1\n",
    "                    else:\n",
    "                        if clothing_bottoms_index == len(clothing_bottoms) - 1:\n",
    "                            clothing_bottoms_index = 0\n",
    "                        else:\n",
    "                            clothing_bottoms_index += 1\n",
    "                        \n",
    "           \n",
    "            if upSwipeDetection(rightWristLocations):\n",
    "                if current_time - last_right_swipe_time > swipe_delay:\n",
    "                    last_right_swipe_time = current_time\n",
    "                    clothing_top_selected = not clothing_top_selected\n",
    "                    if clothing_top_selected: #if the boolean is false that means bottom array selected else top array\n",
    "                        print(\"top array\")\n",
    "                    else:\n",
    "                        print(\"bottom array\")\n",
    "\n",
    "            # swipeDetection(leftWristLocations, rightWristLocations, last_left_swipe_time, last_right_swipe_time, last_up_swipe_time, current_time, clothing_tops_index, clothing_bottoms_index, clothing_top_selected)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during pose estimation or clothing mapping: {e}\")\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "       \n",
    "        # Draw a rectangle at the top of the screen for clothing item display\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        \n",
    "        # Display clothing item name\n",
    "        cv2.putText(image, 'CLOTHING ITEM', (15, 12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        if(clothing_top_selected):\n",
    "            cv2.putText(image, clothing_tops[clothing_tops_index], \n",
    "                        (10, 60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "             cv2.putText(image, clothing_bottoms[clothing_tops_index], \n",
    "                        (10, 60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        # mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "        #                         mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "        #                         mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "        #                          )\n",
    "        \n",
    "        # cv2.imshow('Rotated Frame', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
